{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygdTo50NbsO2"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet google-generativeai langchain_google_genai langchain faiss-cpu openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import google.generativeai as genai\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "import json\n",
        "import re"
      ],
      "metadata": {
        "id": "iP6dQALpb1j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "    Using the provided context, write a detailed Wikihow-style article with a title and numbered steps describing each step to answer the provided question.\n",
        "    Make sure you give a detailed answer with all your knowledge from the given context. Don't answer questions outside of the context.\n",
        "    Context:\\n {context}?\\n\n",
        "    Question: \\n{question}\\n\n",
        "    Answer:\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "PTgeBfU6cHXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_API_KEY'] = \"AIzaSyA90Jp6T4qGE_x0Y3vhV2Qh9bAgr5P94hc\"\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "genai.configure()"
      ],
      "metadata": {
        "id": "dWCKSzCScYwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector_store(text_chunks):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",task_type=\"retrieval_document\")\n",
        "    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
        "    vector_store.save_local(\"faiss_index\")\n",
        "\n",
        "def get_conversational_chain():\n",
        "\n",
        "    prompt_template = PROMPT_TEMPLATE\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
        "\n",
        "    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
        "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "    return chain\n",
        "\n",
        "chain = get_conversational_chain()\n"
      ],
      "metadata": {
        "id": "4huzpRbWhxFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSCRIPT_DIR = 'transcripts/'\n",
        "recipes = []\n",
        "for FILENAME in os.listdir(TRANSCRIPT_DIR):\n",
        "    print(FILENAME)\n",
        "    text = open(TRANSCRIPT_DIR+FILENAME, \"r\").read()\n",
        "    recipes.append(text)\n",
        "\n",
        "get_vector_store(recipes)"
      ],
      "metadata": {
        "id": "ROW1GERJcr98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c31c29-a735-4865-e5ef-dd178a314126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Secret to Jacques Pépins Juicy Chicken a la Susie Recipe ｜ Cooking at Home  ｜ KQED.txt\n",
            "Roast Turkey, Gravy, and Stuffing ｜ Jacques Pépin Cooking At Home ｜ KQED.txt\n",
            "Mouth-watering Lamb Chop with Mushrooms Recipe ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "How to Make Mayonnaise at Home ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "Jacques Pépins Meringue Cookie Recipe - Only Needs 2 Ingredients! ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques  Pépins Secret to Tasty Pasta Fagioli Recipe ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques  Pépins Hearty Kidney Bean Stew Recipe ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques Pépins Chicken Thighs with Garlic Spinach - Easy and Delicious!  ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques Pépins Delicious Seared Shrimp in Shell Recipe ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques Pépins Vegetable Couscous is a Healthy Start to the New Year ｜ Cooking at Home  ｜ KQED.txt\n",
            "James Beards Famous Onion Sandwich Recipe ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "Simplest Green Salad ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "Buttery Shrimp Gratin from Jacques Pépin ｜ Cooking at Home  ｜ KQED.txt\n",
            "Comforting Pea Pod Soup ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "The Secret to Perfectly Cooked Eggs ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "Try Jacques  Pépins Salmon Pizza Recipe - Easy and Tasty! ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques  Pépins Cozy Potato Leek Soup Recipe ｜ Cooking at Home  ｜ KQED.txt\n",
            "Jacques Pépins Vermicelli Soup is the Perfect Winter Recipe ｜ Cooking at Home  ｜ KQED.txt\n",
            "Try These Oven-baked French Fries ｜ Jacques Pépin Cooking at Home  ｜ KQED.txt\n",
            "Sick of Salad Try Jacques Pépins Zucchini Fans ｜ Cooking at Home  ｜ KQED.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(user_question):\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
        "\n",
        "    new_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
        "    docs = new_db.similarity_search(user_question)\n",
        "\n",
        "\n",
        "    response = chain(\n",
        "        {\"input_documents\":docs, \"question\": user_question}\n",
        "        , return_only_outputs=True)\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "0gxp4khLikMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "\n",
        "def get_image(prmpt):\n",
        "  response = client.images.generate(\n",
        "    model=\"dall-e-3\",\n",
        "    prompt=prmpt,\n",
        "    n=1\n",
        "  )\n",
        "  return response.data[0].url"
      ],
      "metadata": {
        "id": "nYiP42bY8zFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_markdown(text):\n",
        "  text = text.replace('•', ' *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "def user_input(user_question, show_img = True):\n",
        "    res = get_response(user_question)['output_text']\n",
        "    if(show_img==False):\n",
        "      return display_markdown(res)\n",
        "\n",
        "    try:\n",
        "      title = res.partition('\\n')[0]\n",
        "      imgUrl = get_image(title)\n",
        "      index = res.find('\\n')\n",
        "      imgStr = \"\\n <img src=\\\"\" + imgUrl +\"\\\"> \\n\"\n",
        "      part1 = res[:index]\n",
        "      part2 = res[index:]\n",
        "      res = part1+imgStr+part2\n",
        "      return display_markdown(res)\n",
        "    except:\n",
        "      return display_markdown(res)"
      ],
      "metadata": {
        "id": "L3RblGynp5-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input(\"How to make chole bhature\",show_img=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "-4OUmC_8-bLs",
        "outputId": "8aadfdac-9c74-4b9e-c8ce-b9d659e0bade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'user_input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3c3abbf36caa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0muser_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How to make chole bhature\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'user_input' is not defined"
          ]
        }
      ]
    }
  ]
}